{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63371f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "#groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6403a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002E29FD452D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002E29FD449A0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(api_key=groq_api_key, model=\"llama-3.1-8b-instant\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b508108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Soumen. As a DevOps Engineer, you likely play a crucial role in ensuring the smooth operation of software systems, from development to deployment and maintenance. What specific areas of DevOps interest you the most, or what are some of the current projects you're working on?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 49, 'total_tokens': 110, 'completion_time': 0.082118766, 'prompt_time': 0.002284813, 'queue_time': 0.049535387, 'total_time': 0.084403579}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ac5c5838-ffd5-464e-9371-21cc76e5f6f6-0', usage_metadata={'input_tokens': 49, 'output_tokens': 61, 'total_tokens': 110})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "messages = [HumanMessage(content=\"Hi, My name is Soumen and I ma a Devops Engineer\")]\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a80eceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Soumen, and you are a DevOps Engineer.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 130, 'total_tokens': 145, 'completion_time': 0.019623181, 'prompt_time': 0.00705874, 'queue_time': 0.049742736, 'total_time': 0.026681921}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--b92a94ee-1c7c-40a0-ada2-3bd7057e7150-0', usage_metadata={'input_tokens': 130, 'output_tokens': 15, 'total_tokens': 145})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Soumen and I ma a Devops Engineer.\"),\n",
    "        AIMessage(content=\"Nice to meet you, Soumen. As a DevOps Engineer, you likely play a crucial role in ensuring the smooth operation of software systems, from development to deployment and maintenance. What specific areas of DevOps interest you the most, or what are some of the current projects you're working on?\"),\n",
    "        HumanMessage(content=\"Hey Whats my name and what do I do?\"),\n",
    "   ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ecdf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory(session_id=session_id)\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    model,\n",
    "    get_session_history\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa99b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2211ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Soumen and I ma a Devops Engineer.\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a510fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Welcome back, Soumen. It seems like we had a brief conversation earlier. As a DevOps Engineer, you must be always on the lookout for ways to improve the efficiency, scalability, and reliability of software systems.\\n\\nWhat challenges have you been facing lately in your role, or is there something specific you'd like to discuss or learn more about? I'm here to help and share knowledge.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20c8ab44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Soumen.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 431, 'total_tokens': 438, 'completion_time': 0.008950108, 'prompt_time': 0.023704553, 'queue_time': 0.050297247, 'total_time': 0.032654661}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--b4238f79-3d18-4d9f-937f-549069b3bbe3-0', usage_metadata={'input_tokens': 431, 'output_tokens': 7, 'total_tokens': 438})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a89d6bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As I mentioned earlier, I don't have any information about your name. You can share it with me if you'd like, or we can continue the conversation without using your name. I'm here to help with any questions or topics you'd like to discuss.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config and session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8839f451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Ishayuth. It's great to know a bit more about you. As a software engineer, you likely work on developing and maintaining software systems, which can be challenging and rewarding at the same time. What kind of software do you typically work on, and what areas of software engineering interest you the most?\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is Ishayuth and I am a Software Engineer.\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf2730de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Ishayuth.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 312, 'total_tokens': 320, 'completion_time': 0.009511838, 'prompt_time': 0.017269389, 'queue_time': 0.054633236, 'total_time': 0.026781227}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--33dcfdbb-1aa4-4392-b668-243df6ad54e0-0', usage_metadata={'input_tokens': 312, 'output_tokens': 8, 'total_tokens': 320})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
