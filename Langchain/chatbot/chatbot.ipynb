{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63371f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "#groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6403a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002E29FD452D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002E29FD449A0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(api_key=groq_api_key, model=\"llama-3.1-8b-instant\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b508108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Soumen. As a DevOps Engineer, you likely play a crucial role in ensuring the smooth operation of software systems, from development to deployment and maintenance. What specific areas of DevOps interest you the most, or what are some of the current projects you're working on?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 49, 'total_tokens': 110, 'completion_time': 0.082118766, 'prompt_time': 0.002284813, 'queue_time': 0.049535387, 'total_time': 0.084403579}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ac5c5838-ffd5-464e-9371-21cc76e5f6f6-0', usage_metadata={'input_tokens': 49, 'output_tokens': 61, 'total_tokens': 110})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "messages = [HumanMessage(content=\"Hi, My name is Soumen and I ma a Devops Engineer\")]\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a80eceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Soumen, and you are a DevOps Engineer.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 130, 'total_tokens': 145, 'completion_time': 0.019623181, 'prompt_time': 0.00705874, 'queue_time': 0.049742736, 'total_time': 0.026681921}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--b92a94ee-1c7c-40a0-ada2-3bd7057e7150-0', usage_metadata={'input_tokens': 130, 'output_tokens': 15, 'total_tokens': 145})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Soumen and I ma a Devops Engineer.\"),\n",
    "        AIMessage(content=\"Nice to meet you, Soumen. As a DevOps Engineer, you likely play a crucial role in ensuring the smooth operation of software systems, from development to deployment and maintenance. What specific areas of DevOps interest you the most, or what are some of the current projects you're working on?\"),\n",
    "        HumanMessage(content=\"Hey Whats my name and what do I do?\"),\n",
    "   ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ecdf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory(session_id=session_id)\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    model,\n",
    "    get_session_history\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa99b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2211ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Soumen and I ma a Devops Engineer.\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a510fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Welcome back, Soumen. It seems like we had a brief conversation earlier. As a DevOps Engineer, you must be always on the lookout for ways to improve the efficiency, scalability, and reliability of software systems.\\n\\nWhat challenges have you been facing lately in your role, or is there something specific you'd like to discuss or learn more about? I'm here to help and share knowledge.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20c8ab44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Soumen.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 431, 'total_tokens': 438, 'completion_time': 0.008950108, 'prompt_time': 0.023704553, 'queue_time': 0.050297247, 'total_time': 0.032654661}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--b4238f79-3d18-4d9f-937f-549069b3bbe3-0', usage_metadata={'input_tokens': 431, 'output_tokens': 7, 'total_tokens': 438})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a89d6bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Ishayuth.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config and session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8839f451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It looks like we're back to where we started. You're Ishayuth, a software engineer. I remember from our previous conversation. How's your day going, and is there something specific you'd like to talk about or ask about in the world of software engineering?\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is Ishayuth and I am a Software Engineer.\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf2730de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Ishayuth.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 435, 'total_tokens': 443, 'completion_time': 0.00385994, 'prompt_time': 0.023916582, 'queue_time': 0.048360418, 'total_time': 0.027776522}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--fce9f1cd-6b89-40b0-9fc8-dda252314dd8-0', usage_metadata={'input_tokens': 435, 'output_tokens': 8, 'total_tokens': 443})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7873484",
   "metadata": {},
   "source": [
    "Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77e1ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(  [\n",
    "   (\"system\", \"You are a helpful assistant .Answer the questions based on the conversation history.\"),\n",
    "   MessagesPlaceholder(variable_name=\"messages\")\n",
    "]\n",
    ")\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83d92c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you Soumen, a DevOps Engineer, that's a fascinating role. What brings you here today? Are you looking for advice on a specific project or tool, or perhaps some guidance on a challenge you're facing in your role?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 65, 'total_tokens': 116, 'completion_time': 0.07793899, 'prompt_time': 0.004109729, 'queue_time': 0.058278631, 'total_time': 0.082048719}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--be1907ba-cbae-4f42-98fc-dc630eb9dcb9-0', usage_metadata={'input_tokens': 65, 'output_tokens': 51, 'total_tokens': 116})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi, My name is Soumen and I ma a Devops Engineer.\")]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c22d6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8716803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Soumen! It's great to know that you're a DevOps Engineer. What brings you here today? Do you have any specific questions or topics you'd like to discuss related to DevOps or anything else?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 105, 'total_tokens': 154, 'completion_time': 0.05229919, 'prompt_time': 0.005631573, 'queue_time': 0.051728967, 'total_time': 0.057930763}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--0643e388-4722-45e0-877a-93f86ec25db7-0', usage_metadata={'input_tokens': 105, 'output_tokens': 49, 'total_tokens': 154})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Soumen and I ma a Devops Engineer.\")],\n",
    "    config=config1\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07c43a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add more complexity to the prompt template\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(  [\n",
    "   (\"system\", \"You are a helpful assistant .Answer the questions based of your ability in {language}\"),\n",
    "   MessagesPlaceholder(variable_name=\"messages\")\n",
    "]\n",
    ")\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0cc4aea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'নমস্কার সৌমেন ভাই, আমি আপনার সহায়ক। আপনার কোনো সমস্যা আছে কিনা তা সম্পর্কে আমাকে জানান।'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi, My name is Soumen \")],\"language\":\"Bengali\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ad1d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ff38c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'আপনার নাম সৌমেন সুন্দর! আমি আপনার সাহায্যের জন্য উপলব্ধ। কী আপনার কথা আছে?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"Hi, My name is Soumen.\")],\"language\":\"Bengali\"},\n",
    "    config=config\n",
    ") \n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28b73740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'আপনার নাম হলো সৌমেন।'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"what is my name?.\")],\"language\":\"Bengali\"},\n",
    "    config=config\n",
    ") \n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b0901d",
   "metadata": {},
   "source": [
    "## Manage the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d473c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's your favorite dessert?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats is 2+2?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='you are welcome', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Yes, I'm having fun! How about you?\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages=[\n",
    "    SystemMessage(content=\"you are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"hi! I am bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like the vanilla ice cream.\"),\n",
    "    AIMessage(content=\"That's great! Vanilla is a classic flavor.\"),\n",
    "    HumanMessage(content=\"What's your favorite dessert?\"),\n",
    "    HumanMessage(content=\"whats is 2+2?\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"you are welcome\"),\n",
    "    HumanMessage(content=\"Having fun?\"),\n",
    "    AIMessage(content=\"Yes, I'm having fun! How about you?\")\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d28750d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(message=itemgetter(\"messages\") | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What is 2+5?\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b88b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap it with message history\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "69722678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have any information about your destination. You didn't mention it earlier. If you'd like to share, I'd be happy to help!\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"Where is my destintion\")],\n",
    "    \"language\":\"English\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
