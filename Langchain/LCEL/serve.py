from fastapi import FastAPI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_groq import ChatGroq
from langserve import add_routes

import os
from dotenv import load_dotenv
load_dotenv()

groq_api_key = os.getenv("GROQ_API_KEY")

model=ChatGroq(
    groq_api_key=groq_api_key, 
    model_name="llama-3.1-8b-instant"
)

#1. Create a prompt template
system_template = "Translate the following into {language}"

prompt_template=ChatPromptTemplate.from_messages([
  ("system", system_template ),
  ("user", "{text}")  
])

#2. Create an output parser
parser = StrOutputParser()

#3. Create a chain using LCEL
chain = prompt_template | model | parser

## App definition
app = FastAPI(
  title="LangChain Server",
  version="1.0",
  description="A simple API server using Langchain runnable interfaces"
)

## Adding chain route

add_routes(app, chain, path="/chain")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)
    
    
    
